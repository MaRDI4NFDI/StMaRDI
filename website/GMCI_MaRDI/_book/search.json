[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Graphical Modelling and Causal Inference",
    "section": "",
    "text": "About\nWithin MaRDI, we aim to create a platform and public service to support and foster mathematical research. This comprises the development of good research practices, providing tools for establishing interconnections of research via unique digital tokens, and creating databases for immediate access to key resources of the mathematical research community.\nWe host the Zenodo community Graphical Modelling and Causal Inference. On this platform, we curate and present topical datasets and metadata. Exemplary statistical notebooks showcase advances in methodology and present new applications. The community supports content-moderation by our TA, and we will encourage and solicit submissions of datasets and notebooks by researchers from the broader academic community.",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Zenodo Search",
    "section": "",
    "text": "Searching in Zenodo is a logical ‘OR’ and not a logical ‘AND’. We have thus implemented a search option generating URL for an appropriate Zenodo search with javascript. Select the desired attributes and click the button to open an external Zenodo page.\n\n    \n    \n    City Selector\n    \n\n\n    \n        \n            Task\n            \n                 Causal Discovery\n                 Causal Inference\n            \n        \n        \n            Data Type\n            \n                 Continuous\n                 Discrete\n                 Mixed\n                 Binary\n            \n        \n        \n            Dataset Scope\n            \n                 Collection\n                 Standalone\n            \n        \n        \n            Ground Truth\n            \n                 Known\n                 Partial\n                 Unknown\n            \n        \n        \n            License\n            \n                 Research Only\n                 Open\n            \n        \n        \n            Missing Values\n            \n                 Yes\n                 No\n            \n        \n        \n            Temporal Structure\n            \n                 Static\n                 Time Series\n            \n        \n    \n    Generate URL\n    \n\nThe search function is currently not working as planned. E.g. “Missing = Yes” does not return the correct",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Zenodo Search</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Custom Online Data Extraction",
    "section": "",
    "text": "2.1 Economic & Financial Data\nEconomic and financial data often involve causal relationships, such as how inflation affects employment or how policies impact market behavior.\nPossible datasets:\nExample sources:",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Custom Online Data Extraction</span>"
    ]
  },
  {
    "objectID": "summary.html#economic-financial-data",
    "href": "summary.html#economic-financial-data",
    "title": "2  Custom Online Data Extraction",
    "section": "",
    "text": "GDP, inflation, and trade data\nStock market and financial transactions\nHousehold income and economic indicators\n\n\n\nWorld Bank Open Data\nOECD Data\nFederal Reserve Economic Data (FRED)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Custom Online Data Extraction</span>"
    ]
  },
  {
    "objectID": "summary.html#social-behavioral-data",
    "href": "summary.html#social-behavioral-data",
    "title": "2  Custom Online Data Extraction",
    "section": "2.2 Social & Behavioral Data",
    "text": "2.2 Social & Behavioral Data\nUnderstanding human behavior, social interactions, and cultural influences can be crucial in causal inference.\nPossible datasets:\n\nSocial network analysis (Facebook, Twitter datasets)\nBehavioral economics studies\nSocial mobility and inequality data\n\nExample sources:\n\nGeneral Social Survey (GSS)\nPew Research Data\nEuropean Social Survey (ESS)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Custom Online Data Extraction</span>"
    ]
  },
  {
    "objectID": "summary.html#environmental-ecological-data",
    "href": "summary.html#environmental-ecological-data",
    "title": "2  Custom Online Data Extraction",
    "section": "2.3 Environmental & Ecological Data",
    "text": "2.3 Environmental & Ecological Data\nClimate change, pollution, and biodiversity studies require causal modeling for impact assessment.\nPossible datasets:\n\nClimate change and greenhouse gas emissions\nBiodiversity and species distribution\nAir and water quality\n\nExample sources:\n\nNASA Earth Data\nCopernicus Climate Data\nGlobal Biodiversity Information Facility (GBIF)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Custom Online Data Extraction</span>"
    ]
  },
  {
    "objectID": "summary.html#engineering-sensor-data",
    "href": "summary.html#engineering-sensor-data",
    "title": "2  Custom Online Data Extraction",
    "section": "2.4 Engineering & Sensor Data",
    "text": "2.4 Engineering & Sensor Data\nSensor-based datasets (IoT, industrial processes, robotics) can provide time-series data for causal discovery.\nPossible datasets:\n\nSmart cities and traffic monitoring\nIndustrial machine failure predictions\nEnergy consumption and grid stability\n\nExample sources:\n\nOpenML\nUCI Machine Learning Repository",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Custom Online Data Extraction</span>"
    ]
  },
  {
    "objectID": "summary.html#political-legal-data",
    "href": "summary.html#political-legal-data",
    "title": "2  Custom Online Data Extraction",
    "section": "2.5 Political & Legal Data",
    "text": "2.5 Political & Legal Data\nCausal models can analyze policy effects, election predictions, and legal case outcomes.\nPossible datasets:\n\nElection results and voter behavior\nGovernment spending and policy impact\nLegal case rulings and sentencing patterns\n\nExample sources:\n\nCongressional Voting Records\nComparative Political Data Set (CPDS)\nWorld Justice Project Rule of Law Index",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Custom Online Data Extraction</span>"
    ]
  },
  {
    "objectID": "summary.html#transportation-mobility-data",
    "href": "summary.html#transportation-mobility-data",
    "title": "2  Custom Online Data Extraction",
    "section": "2.6 Transportation & Mobility Data",
    "text": "2.6 Transportation & Mobility Data\nCausal analysis in urban planning, traffic patterns, and logistics is crucial for optimizing transport systems.\nPossible datasets:\n\nPublic transportation ridership data\nRoad traffic and accident reports\nFlight delays and logistics performance\n\nExample sources:\n\nU.S. Department of Transportation Open Data\nNYC Open Data (Taxi & Traffic Data)\nOpenStreetMap Traffic Data",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Custom Online Data Extraction</span>"
    ]
  },
  {
    "objectID": "summary.html#education-data",
    "href": "summary.html#education-data",
    "title": "2  Custom Online Data Extraction",
    "section": "2.7 Education Data",
    "text": "2.7 Education Data\nEducational outcomes are often influenced by multiple factors (socioeconomic status, school policies, etc.), making them ideal for causal modeling.\nPossible datasets:\n\nStudent performance and test scores\nSchool funding and academic achievement\nHigher education statistics\n\nExample sources:\n\nNational Center for Education Statistics (NCES)\nOECD Education at a Glance",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Custom Online Data Extraction</span>"
    ]
  },
  {
    "objectID": "summary.html#crime-justice-data",
    "href": "summary.html#crime-justice-data",
    "title": "2  Custom Online Data Extraction",
    "section": "2.8 Crime & Justice Data",
    "text": "2.8 Crime & Justice Data\nUnderstanding the causal effects of policies, policing, and social factors on crime rates is crucial.\nPossible datasets:\n\nCrime rates and law enforcement reports\nPrison population statistics\nImpact of social programs on crime reduction\n\nExample sources:\n\nFBI Crime Data Explorer\nBureau of Justice Statistics (BJS)\nUK Crime Data",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Custom Online Data Extraction</span>"
    ]
  },
  {
    "objectID": "summary.html#energy-sustainability-data",
    "href": "summary.html#energy-sustainability-data",
    "title": "2  Custom Online Data Extraction",
    "section": "2.9 Energy & Sustainability Data",
    "text": "2.9 Energy & Sustainability Data\nCausal relationships between energy consumption, economic growth, and environmental policies are important.\nPossible datasets:\n\nRenewable energy production\nElectricity grid performance\nCarbon footprint analysis\n\nExample sources:\n\nInternational Energy Agency (IEA)\nOur World in Data – Energy\nU.S. Energy Information Administration (EIA)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Custom Online Data Extraction</span>"
    ]
  },
  {
    "objectID": "summary.html#further-categories",
    "href": "summary.html#further-categories",
    "title": "2  Custom Online Data Extraction",
    "section": "2.10 Further Categories",
    "text": "2.10 Further Categories\nWe will add sources for the categories\n*Gene expression data * health data * meterological data * psychological data * population data * biological data * pharmaceutical data",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Custom Online Data Extraction</span>"
    ]
  },
  {
    "objectID": "gallery/notebook1.html",
    "href": "gallery/notebook1.html",
    "title": "3  Gaussian Linear Model",
    "section": "",
    "text": "Random plotting of a linear Gaussian model\n\nset.seed(1234)\nn &lt;- 1000\nx &lt;- rnorm(n)\ny &lt;- x * 3 + rnorm(n, 0, 0.75)\nplot(x, y)",
    "crumbs": [
      "Accompanying Statistical Notebooks",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Gaussian Linear Model</span>"
    ]
  },
  {
    "objectID": "gallery/notebook2.html",
    "href": "gallery/notebook2.html",
    "title": "4  ALARM Notebook",
    "section": "",
    "text": "Alarm dataset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlarm dataset\nOleksandr Zadorozhnyi\n\n\n\n\nSetup of the problem \nIn the context of graphical modeling and structure learning from data\nwe consider a simple task of determining the most appropriate graphical\nstructure for a Bayesian network model (DAG estimation) based on the\navailable data. This problem is fundamental in probabilistic graphical\nmodeling, and it involves identifying the conditional dependencies\nbetween variables in the dataset, which are represented by edges (arcs)\nin the Bayesian network.\nIn this notebook we perform a simple experiment to estimate the\nstructure between the covariates from the (subset) of dataset\n“alarm”.\nLoading the required libraries.\nlibrary(bnlearn)\nlibrary(qgraph)\nlibrary(\"huge\")\nlibrary(ggplot2)\nlibrary(tidyverse)\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.4     ✔ tibble    3.2.1\n✔ purrr     1.0.4     ✔ tidyr     1.3.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\nLoading the data from Zenodo collection/community:\n# necessary libraries to use for Zenodo REST-API\nlibrary(zen4R)\n\nzenodo &lt;- ZenodoManager$new(\n  logger = \"INFO\" # use \"DEBUG\" to see detailed API operation logs, use NULL if you don't want logs at all\n)\n\n# downloading files using zenodo doi and reading from the file \nrec1 &lt;- zenodo$getRecordByDOI(\"10.5281/zenodo.7676616\")\n[zen4R][INFO] ZenodoRequest - Fetching https://zenodo.org/api/records?q=doi:%2210.5281/zenodo.7676616%22&size=10&page=1&allversions=1 \nℹ Successfully fetched list of published records - page 1\n[zen4R][INFO] ZenodoManager - Successfully fetched list of published records - page 1 \n✔ Successfully fetched list of published records!\n[zen4R][INFO] ZenodoManager - Successfully fetched list of published records! \n✔ Successfully fetched record for DOI '10.5281/zenodo.7676616'!\n[zen4R][INFO] ZenodoManager - Successfully fetched record for DOI '10.5281/zenodo.7676616'! \nfiles &lt;- rec1$listFiles(pretty = TRUE)\n\n#create a folder where to download files from record\ndir.create(\"download_zenodo\")\nWarning in dir.create(\"download_zenodo\"): 'download_zenodo' already exists\n#download files\nrec1$downloadFiles(path = \"download_zenodo\")\nℹ Download in sequential mode\n[zen4R][INFO] ZenodoRecord - Download in sequential mode \nℹ Will download 1 file from record '7676616' (doi: '10.5281/zenodo.7676616') - total size: 2 MiB\n[zen4R][INFO] ZenodoRecord - Will download 1 file from record '7676616' (doi: '10.5281/zenodo.7676616') - total size: 2 MiB \nℹ Downloading file 'bnlearn_data.zip' - size: 2 MiB\n[zen4R][INFO] Downloading file 'bnlearn_data.zip' - size: 2 MiB\nℹ File downloaded at '/Users/mareis/Documents/projects/MaRDI/StMaRDI/website/GMCI_MaRDI/gallery/download_zenodo'.\n[zen4R][INFO] File downloaded at '/Users/mareis/Documents/projects/MaRDI/StMaRDI/website/GMCI_MaRDI/gallery/download_zenodo'.\nℹ Verifying file integrity...\n[zen4R][INFO] ZenodoRecord - Verifying file integrity... \nℹ File 'bnlearn_data.zip': integrity verified (md5sum: f123ea701227cfd8a43996183b7c5279)\n[zen4R][INFO] File 'bnlearn_data.zip': integrity verified (md5sum: f123ea701227cfd8a43996183b7c5279)\n✔ End of download\n[zen4R][INFO] ZenodoRecord - End of download \ndownloaded_files &lt;- list.files(\"download_zenodo\")\n\nzipF = sprintf(\"download_zenodo/%s\",downloaded_files)\n\n# unzipping in the current folder\nunzip(zipF,exdir = \"./\")\n\nalarm_name = list.files(tools::file_path_sans_ext(downloaded_files))[1]\n\npath_to_file = paste0(tools::file_path_sans_ext(downloaded_files),\"/\",alarm_name,\"/\",alarm_name,\".csv\")\n\ndf = read.csv(path_to_file)\nhead(df)\n     CVP   PCWP  HIST    TPR     BP     CO HRBP HREK HRSA    PAP   SAO2   FIO2\n1 NORMAL NORMAL FALSE    LOW NORMAL   HIGH HIGH HIGH HIGH NORMAL NORMAL    LOW\n2 NORMAL NORMAL FALSE NORMAL    LOW    LOW HIGH HIGH HIGH NORMAL    LOW NORMAL\n3 NORMAL   HIGH FALSE NORMAL NORMAL   HIGH HIGH HIGH HIGH NORMAL    LOW NORMAL\n4 NORMAL NORMAL FALSE    LOW    LOW   HIGH HIGH HIGH HIGH NORMAL NORMAL NORMAL\n5 NORMAL NORMAL FALSE    LOW    LOW NORMAL HIGH HIGH HIGH NORMAL    LOW NORMAL\n6 NORMAL NORMAL FALSE    LOW NORMAL   HIGH HIGH HIGH HIGH NORMAL    LOW NORMAL\n    PRSS ECO2 MINV    MVS   HYP   LVF   APL  ANES   PMB    INT  KINK  DISC\n1   HIGH ZERO HIGH NORMAL FALSE FALSE FALSE FALSE FALSE NORMAL FALSE  TRUE\n2   HIGH ZERO ZERO NORMAL FALSE FALSE FALSE FALSE FALSE NORMAL FALSE FALSE\n3 NORMAL ZERO ZERO NORMAL FALSE FALSE FALSE FALSE FALSE NORMAL FALSE FALSE\n4   HIGH ZERO ZERO NORMAL FALSE FALSE FALSE FALSE FALSE NORMAL FALSE FALSE\n5    LOW ZERO ZERO NORMAL FALSE FALSE FALSE FALSE FALSE NORMAL FALSE FALSE\n6   HIGH HIGH ZERO NORMAL FALSE FALSE FALSE  TRUE FALSE NORMAL FALSE FALSE\n     LVV   STKV CCHL  ERLO   HR  ERCA   SHNT    PVS   ACO2 VALV VLNG VTUB\n1 NORMAL NORMAL HIGH FALSE HIGH FALSE NORMAL NORMAL NORMAL HIGH  LOW ZERO\n2 NORMAL    LOW HIGH FALSE HIGH FALSE NORMAL    LOW    LOW ZERO ZERO  LOW\n3 NORMAL NORMAL HIGH FALSE HIGH FALSE NORMAL    LOW    LOW ZERO ZERO  LOW\n4 NORMAL NORMAL HIGH FALSE HIGH FALSE NORMAL NORMAL    LOW ZERO ZERO  LOW\n5 NORMAL NORMAL HIGH FALSE HIGH FALSE NORMAL    LOW    LOW ZERO ZERO  LOW\n6 NORMAL NORMAL HIGH FALSE HIGH FALSE NORMAL    LOW    LOW ZERO ZERO  LOW\n    VMCH\n1 NORMAL\n2 NORMAL\n3 NORMAL\n4 NORMAL\n5 NORMAL\n6 NORMAL\nWe need to transform data first\nfor (item in colnames(df)){\n  df[,item] = as.factor(df[,item])\n}\nDescription of the data.\nThe ALARM (“A Logical Alarm Reduction Mechanism”) is a Bayesian\nnetwork designed to provide an alarm message system for patient\nmonitoring.\nThe alarm data set contains the following 37 variables\n:\nCVP (central venous pressure): a three-level factor with levels LOW, NORMAL and HIGH.\n\nPCWP (pulmonary capillary wedge pressure): a three-level factor with levels LOW, NORMAL and HIGH.\n\nHIST (history): a two-level factor with levels TRUE and FALSE.\n\nTPR (total peripheral resistance): a three-level factor with levels LOW, NORMAL and HIGH.\n\nBP (blood pressure): a three-level factor with levels LOW, NORMAL and HIGH.\n\nCO (cardiac output): a three-level factor with levels LOW, NORMAL and HIGH.\n\nHRBP (heart rate / blood pressure): a three-level factor with levels LOW, NORMAL and HIGH.\n\nHREK (heart rate measured by an EKG monitor): a three-level factor with levels LOW, NORMAL and HIGH.\n\nHRSA (heart rate / oxygen saturation): a three-level factor with levels LOW, NORMAL and HIGH.\n\nPAP (pulmonary artery pressure): a three-level factor with levels LOW, NORMAL and HIGH.\n\nSAO2 (arterial oxygen saturation): a three-level factor with levels LOW, NORMAL and HIGH.\n\nFIO2 (fraction of inspired oxygen): a two-level factor with levels LOW and NORMAL.\n\nPRSS (breathing pressure): a four-level factor with levels ZERO, LOW, NORMAL and HIGH.\n\nECO2 (expelled CO2): a four-level factor with levels ZERO, LOW, NORMAL and HIGH.\n\nMINV (minimum volume): a four-level factor with levels ZERO, LOW, NORMAL and HIGH.\n\nMVS (minimum volume set): a three-level factor with levels LOW, NORMAL and HIGH.\n\nHYP (hypovolemia): a two-level factor with levels TRUE and FALSE.\n\nLVF (left ventricular failure): a two-level factor with levels TRUE and FALSE.\n\nAPL (anaphylaxis): a two-level factor with levels TRUE and FALSE.\n\nANES (insufficient anesthesia/analgesia): a two-level factor with levels TRUE and FALSE.\n\nPMB (pulmonary embolus): a two-level factor with levels TRUE and FALSE.\n\nINT (intubation): a three-level factor with levels NORMAL, ESOPHAGEAL and ONESIDED.\n\nKINK (kinked tube): a two-level factor with levels TRUE and FALSE.\n\nDISC (disconnection): a two-level factor with levels TRUE and FALSE.\n\nLVV (left ventricular end-diastolic volume): a three-level factor with levels LOW, NORMAL and HIGH.\n\nSTKV (stroke volume): a three-level factor with levels LOW, NORMAL and HIGH.\n\nCCHL (catecholamine): a two-level factor with levels NORMAL and HIGH.\n\nERLO (error low output): a two-level factor with levels TRUE and FALSE.\n\nHR (heart rate): a three-level factor with levels LOW, NORMAL and HIGH.\n\nERCA (electrocauter): a two-level factor with levels TRUE and FALSE.\n\nSHNT (shunt): a two-level factor with levels NORMAL and HIGH.\n\nPVS (pulmonary venous oxygen saturation): a three-level factor with levels LOW, NORMAL and HIGH.\n\nACO2 (arterial CO2): a three-level factor with levels LOW, NORMAL and HIGH.\n\nVALV (pulmonary alveoli ventilation): a four-level factor with levels ZERO, LOW, NORMAL and HIGH.\n\nVLNG (lung ventilation): a four-level factor with levels ZERO, LOW, NORMAL and HIGH.\n\nVTUB (ventilation tube): a four-level factor with levels ZERO, LOW, NORMAL and HIGH.\n\nVMCH (ventilation machine): a four-level factor with levels ZERO, LOW, NORMAL and HIGH.\nTransforming the data to decode the categorical values as\nintegers.\nalarm_df &lt;- as.data.frame(na.omit(df))\n\np = length(names(df))\nn = dim(df)[1]\n for (i in c(1:p)) {\n     alarm_df[,i]&lt;-as.numeric(alarm_df[,i])\n}\nApplying nonparanormal transformation to standardize the data. More\nprecisely it transforms the data using the truncated empirical\nprobability distribution function and the final re-normalization.\nselection &lt;- c(\"TPR\",\"PMB\",\"VTUB\",\"VLNG\",\"CO\")\n\n\n#alarm_df &lt;- huge.npn(alarm_df)\nalarm_df_npn = huge.npn(alarm_df)\nConducting the nonparanormal (npn) transformation via shrunkun ECDF....done.\nhead(alarm_df_npn)\n        CVP       PCWP        HIST        TPR        BP         CO       HRBP\n1 0.5073642  0.6137092 -0.09973971 -0.1768279 1.7013279 -0.8713625 -0.6646985\n2 0.5073642  0.6137092 -0.09973971  1.2401612 0.2199787  0.5248706 -0.6646985\n3 0.5073642 -1.8179024 -0.09973971  1.2401612 1.7013279 -0.8713625 -0.6646985\n4 0.5073642  0.6137092 -0.09973971 -0.1768279 0.2199787 -0.8713625 -0.6646985\n5 0.5073642  0.6137092 -0.09973971 -0.1768279 0.2199787  1.6119505 -0.6646985\n6 0.5073642  0.6137092 -0.09973971 -0.1768279 1.7013279 -0.8713625 -0.6646985\n        HREK       HRSA       PAP      SAO2        FIO2       PRSS      ECO2\n1 -0.7062245 -0.7035549 0.1981972 3.1144053 -2.84981107 -0.9524646  0.673732\n2 -0.7062245 -0.7035549 0.1981972 0.2543214  0.09241588 -0.9524646  0.673732\n3 -0.7062245 -0.7035549 0.1981972 0.2543214  0.09241588  1.6472706  0.673732\n4 -0.7062245 -0.7035549 0.1981972 3.1144053  0.09241588 -0.9524646  0.673732\n5 -0.7062245 -0.7035549 0.1981972 0.2543214  0.09241588  0.5257479  0.673732\n6 -0.7062245 -0.7035549 0.1981972 0.2543214  0.09241588 -0.9524646 -3.066870\n        MINV      MVS        HYP         LVF         APL       ANES        PMB\n1 -1.9144844 0.190179 -0.3735556 -0.09049377 -0.01845303 -0.1917453 -0.0187271\n2  0.5310157 0.190179 -0.3735556 -0.09049377 -0.01845303 -0.1917453 -0.0187271\n3  0.5310157 0.190179 -0.3735556 -0.09049377 -0.01845303 -0.1917453 -0.0187271\n4  0.5310157 0.190179 -0.3735556 -0.09049377 -0.01845303 -0.1917453 -0.0187271\n5  0.5310157 0.190179 -0.3735556 -0.09049377 -0.01845303 -0.1917453 -0.0187271\n6  0.5310157 0.190179 -0.3735556 -0.09049377 -0.01845303  2.3652828 -0.0187271\n          INT        KINK       DISC       LVV       STKV       CCHL       ERLO\n1 -0.03581248 -0.06643384  2.4071300 0.5699623  0.4078339 -0.4523933 -0.0915921\n2 -0.03581248 -0.06643384 -0.1806935 0.5699623 -1.6350478 -0.4523933 -0.0915921\n3 -0.03581248 -0.06643384 -0.1806935 0.5699623  0.4078339 -0.4523933 -0.0915921\n4 -0.03581248 -0.06643384 -0.1806935 0.5699623  0.4078339 -0.4523933 -0.0915921\n5 -0.03581248 -0.06643384 -0.1806935 0.5699623  0.4078339 -0.4523933 -0.0915921\n6 -0.03581248 -0.06643384 -0.1806935 0.5699623  0.4078339 -0.4523933 -0.0915921\n          HR       ERCA     SHNT      PVS       ACO2      VALV       VLNG\n1 -0.5839908 -0.1820744 0.188705 3.335150  2.2090134 -1.919255 -1.6005522\n2 -0.5839908 -0.1820744 0.188705 0.284708 -0.2197939  0.573119  0.4766123\n3 -0.5839908 -0.1820744 0.188705 0.284708 -0.2197939  0.573119  0.4766123\n4 -0.5839908 -0.1820744 0.188705 3.335150 -0.2197939  0.573119  0.4766123\n5 -0.5839908 -0.1820744 0.188705 0.284708 -0.2197939  0.573119  0.4766123\n6 -0.5839908 -0.1820744 0.188705 0.284708 -0.2197939  0.573119  0.4766123\n       VTUB     VMCH\n1  1.903289 0.124569\n2 -0.274845 0.124569\n3 -0.274845 0.124569\n4 -0.274845 0.124569\n5 -0.274845 0.124569\n6 -0.274845 0.124569\nSubselecting certain variables for analysis. Splitting the data set\ninto the train (structure estimation) and the dataset for inference\n(given the structure of the estimated graph) on the particular\ncovariate. Correlation maps of the given sub-selection of variables is\npresented.\nWarning: The `x` argument of `as_tibble.matrix()` must have unique column names if\n`.name_repair` is omitted as of tibble 2.0.0.\nℹ Using compatibility `.name_repair`.\n\nDefining the true network structure for the alarm dataset (see paper\n“Learning Bayesian Networks with the bnlearn R Package” by\nM.Scutari)\ndag_alarm &lt;- empty.graph(names(alarm))\nmodelstring(dag_alarm) &lt;- paste(\"[HIST|LVF][CVP|LVV][PCWP|LVV][HYP][LVV|HYP:LVF]\",\"[LVF][STKV|HYP:LVF][ERLO][HRBP|ERLO:HR][HREK|ERCA:HR][ERCA][HRSA|ERCA:HR]\",\"[ANES][APL][TPR|APL][ECO2|ACO2:VLNG][KINK][MINV|INT:VLNG][FIO2]\",\"[PVS|FIO2:VALV][SAO2|PVS:SHNT][PAP|PMB][PMB][SHNT|INT:PMB][INT]\",\"[PRSS|INT:KINK:VTUB][DISC][MVS][VMCH|MVS][VTUB|DISC:VMCH]\",\"[VLNG|INT:KINK:VTUB][VALV|INT:VLNG][ACO2|VALV][CCHL|ACO2:ANES:SAO2:TPR]\",\"[HR|CCHL][CO|HR:STKV][BP|CO:TPR]\", sep = \"\")\nqgraph(dag_alarm)\n\nSelection of the specific covariates to perform the structure\nestimation and the inference in the model task.\nalarm_dfSubset &lt;-as.data.frame(alarm_df[,selection])\n\nalarm_df_str_est = alarm_dfSubset[str_set,]\nalarm_df_fit = alarm_dfSubset[est_set,]\nhead(alarm_df_str_est)\n  TPR PMB VTUB VLNG CO\n1   2   1    4    2  1\n2   3   1    2    4  2\n3   3   1    2    4  1\n4   2   1    2    4  1\n5   2   1    2    4  3\n6   2   1    2    4  1\nApplying the algorithm pc.stable to the dataset alarm\nRes&lt;-pc.stable(alarm_df_str_est)\n\nbnlearn:::print.bn(Res)\n\n  Bayesian network learned via Constraint-based methods\n\n  model:\n    [partially directed graph]\n  nodes:                                 5 \n  arcs:                                  3 \n    undirected arcs:                     1 \n    directed arcs:                       2 \n  average markov blanket size:           1.60 \n  average neighbourhood size:            1.20 \n  average branching factor:              0.40 \n\n  learning algorithm:                    PC (Stable) \n  conditional independence test:         Pearson's Correlation \n  alpha threshold:                       0.05 \n  tests used in the learning procedure:  28 \nApplying a set of constraint-based algorithms to estimate the DAG\nstructure between the selected variables.\nRes_stable=pc.stable(alarm_df_str_est)\n\nRes_iamb=iamb(alarm_df_str_est)\n\nRes_gs=gs(alarm_df_str_est)\n\nRes_fiamb=fast.iamb(alarm_df_str_est)\n\nRes_mmpc=mmpc(alarm_df_str_est)\nVisualizing the estimated graph with PC-stable algorithm with respect\nto the chosen variables. As we see the pc.stable algorithm returns a\nCPDAG. For the inference purposes we manually set the (undirected) edges\nto specific values.\nLabels &lt;- c(\n  \"Total peripheral resistance\",\n  \"Pulmonary embolus\",\n  \"Ventilation tube\",\n  \"Lung ventilation\",\n  \"Cardiac output\"\n)\n\nqgraph(Res, nodeNames = Labels, legend.cex = 0.35)\n\n# black magic to make it a proper DAG\n\nRes &lt;- set.arc(Res, from = \"PMB\",to=\"CO\")\nRes &lt;- set.arc(Res, from = \"TPR\",to=\"CO\")\nRes = set.arc(Res,from = \"VLNG\",to=\"VTUB\")\n\nRes\n\n  Bayesian network learned via Constraint-based methods\n\n  model:\n   [TPR][PMB][VLNG][VTUB|VLNG][CO|TPR:PMB:VLNG] \n  nodes:                                 5 \n  arcs:                                  4 \n    undirected arcs:                     0 \n    directed arcs:                       4 \n  average markov blanket size:           2.80 \n  average neighbourhood size:            1.60 \n  average branching factor:              0.80 \n\n  learning algorithm:                    PC (Stable) \n  conditional independence test:         Pearson's Correlation \n  alpha threshold:                       0.05 \n  tests used in the learning procedure:  28 \ngraph &lt;- qgraph(Res)\n\nFitting the model to the dataset.\nfit &lt;- bn.fit(Res, alarm_df_fit)\nfit$CO\n\n  Parameters of node CO (Gaussian distribution)\n\nConditional density: CO | TPR + PMB + VLNG\nCoefficients:\n(Intercept)          TPR          PMB         VLNG  \n 2.61248092  -0.39384628   0.01495855  -0.02626200  \nStandard deviation of the residuals: 0.7893206 \nfit$VTUB\n\n  Parameters of node VTUB (Gaussian distribution)\n\nConditional density: VTUB | VLNG\nCoefficients:\n(Intercept)         VLNG  \n  3.2383682   -0.2568879  \nStandard deviation of the residuals: 0.8209566 \nfit$TPR\n\n  Parameters of node TPR (Gaussian distribution)\n\nConditional density: TPR\nCoefficients:\n(Intercept)  \n   2.094853  \nStandard deviation of the residuals: 0.8253788 \nNonparametrical bootstraping of the results of the model.\nset.seed(1)\n\nboot &lt;- boot.strength(as.data.frame(alarm_dfSubset), R = 100, algorithm = \"pc.stable\")\n\nboot\n   from   to strength direction\n1   TPR  PMB     0.69 0.2318841\n2   TPR VTUB     0.05 0.1000000\n3   TPR VLNG     0.00 0.0000000\n4   TPR   CO     1.00 0.4750000\n5   PMB  TPR     0.69 0.7681159\n6   PMB VTUB     0.03 0.5000000\n7   PMB VLNG     0.10 0.5000000\n8   PMB   CO     0.01 1.0000000\n9  VTUB  TPR     0.05 0.9000000\n10 VTUB  PMB     0.03 0.5000000\n11 VTUB VLNG     1.00 0.7200000\n12 VTUB   CO     0.03 0.5000000\n13 VLNG  TPR     0.00 0.0000000\n14 VLNG  PMB     0.10 0.5000000\n15 VLNG VTUB     1.00 0.2800000\n16 VLNG   CO     1.00 0.4600000\n17   CO  TPR     1.00 0.5250000\n18   CO  PMB     0.01 0.0000000\n19   CO VTUB     0.03 0.5000000\n20   CO VLNG     1.00 0.5400000\nqgraph(boot,nodeNames=Labels,legend.cex = 0.35,\n       edge.labels=TRUE,layout=graph$layout,asize=5,\n       edge.color=\"black\")\n\nReferences \n[1] Beinlich I, Suermondt HJ, Chavez RM, Cooper GF (1989). “The ALARM\nMonitoring System: A Case Study with Two Probabilistic Inference\nTechniques for Belief Networks”. Proceedings of the 2nd European\nConference on Artificial Intelligence in Medicine, 247–256. https://doi.org/10.1007/978-3-642-93437-7_28\n[2] Scutari, M. Learning Bayesian Networks with bnlearn R package. https://arxiv.org/pdf/0908.3817.pdf",
    "crumbs": [
      "Accompanying Statistical Notebooks",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ALARM Notebook</span>"
    ]
  },
  {
    "objectID": "gallery/notebook3.html",
    "href": "gallery/notebook3.html",
    "title": "5  ALARM Subgraph Notebook",
    "section": "",
    "text": "Subgraph selection and evaluation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSubgraph selection and evaluation\nDavid Reiffenscheidt and Oleksandr Zadorozhnyi\n12/09/2023\n\n\n\n\nSetup of the problem\nGiven a large graph \\(G = (V, E)\\),\nwhere \\(V\\) represents the set of nodes\nand \\(E\\) represents the set of edges,\nthe goal is to select a subgraph \\(S = (V_s,\nE_s)\\) from G such that S is a meaningful and informative\nrepresentation of the original graph \\(G\\). The subgraph selection problem\ninvolves finding an optimal or near-optimal subgraph that satisfies\ncertain criteria or objectives.\nIn the context of graphical modelling the problem of subgraph\nselection corresponds to the problem of preserving the conditional\nindependence relationship in the subgraph \\(S\\) which has to be transferred from the\nunderlying graph \\(G\\).\nFurthermore, it is important to be able to evaluate the results of\nthe structure learning algorithms (learned on the data) taking as a\nground truth the selected subgraph.\n### loading packages\nlibrary(\"bnlearn\")\nlibrary(\"qgraph\")\nlibrary(\"igraph\")\n\nAttaching package: 'igraph'\nThe following objects are masked from 'package:bnlearn':\n\n    as.igraph, compare, degree, subgraph\nThe following objects are masked from 'package:stats':\n\n    decompose, spectrum\nThe following object is masked from 'package:base':\n\n    union\nlibrary(\"pcalg\")\n\nAttaching package: 'pcalg'\nThe following objects are masked from 'package:bnlearn':\n\n    dsep, pdag2dag, shd, skeleton\nReading the files from Zenodo entry in the community\n# necessary libraries to use for Zenodo REST-API\nlibrary(zen4R)\n\nzenodo &lt;- ZenodoManager$new(\n  logger = \"INFO\" # use \"DEBUG\" to see detailed API operation logs, use NULL if you don't want logs at all\n)\n\n# downloading files using zenodo doi and reading from the file \nrec1 &lt;- zenodo$getRecordByDOI(\"10.5281/zenodo.7676616\")\n[zen4R][INFO] ZenodoRequest - Fetching https://zenodo.org/api/records?q=doi:%2210.5281/zenodo.7676616%22&size=10&page=1&allversions=1 \nℹ Successfully fetched list of published records - page 1\n[zen4R][INFO] ZenodoManager - Successfully fetched list of published records - page 1 \n✔ Successfully fetched list of published records!\n[zen4R][INFO] ZenodoManager - Successfully fetched list of published records! \n✔ Successfully fetched record for DOI '10.5281/zenodo.7676616'!\n[zen4R][INFO] ZenodoManager - Successfully fetched record for DOI '10.5281/zenodo.7676616'! \nfiles &lt;- rec1$listFiles(pretty = TRUE)\n\n#create a folder where to download files from record\ndir.create(\"download_zenodo\")\nWarning in dir.create(\"download_zenodo\"): 'download_zenodo' already exists\n#download files\nrec1$downloadFiles(path = \"download_zenodo\")\nℹ Download in sequential mode\n[zen4R][INFO] ZenodoRecord - Download in sequential mode \nℹ Will download 1 file from record '7676616' (doi: '10.5281/zenodo.7676616') - total size: 2 MiB\n[zen4R][INFO] ZenodoRecord - Will download 1 file from record '7676616' (doi: '10.5281/zenodo.7676616') - total size: 2 MiB \nℹ Downloading file 'bnlearn_data.zip' - size: 2 MiB\n[zen4R][INFO] Downloading file 'bnlearn_data.zip' - size: 2 MiB\nℹ File downloaded at '/Users/mareis/Documents/projects/MaRDI/StMaRDI/website/GMCI_MaRDI/gallery/download_zenodo'.\n[zen4R][INFO] File downloaded at '/Users/mareis/Documents/projects/MaRDI/StMaRDI/website/GMCI_MaRDI/gallery/download_zenodo'.\nℹ Verifying file integrity...\n[zen4R][INFO] ZenodoRecord - Verifying file integrity... \nℹ File 'bnlearn_data.zip': integrity verified (md5sum: f123ea701227cfd8a43996183b7c5279)\n[zen4R][INFO] File 'bnlearn_data.zip': integrity verified (md5sum: f123ea701227cfd8a43996183b7c5279)\n✔ End of download\n[zen4R][INFO] ZenodoRecord - End of download \ndownloaded_files &lt;- list.files(\"download_zenodo\")\n\nzipF = sprintf(\"download_zenodo/%s\",downloaded_files)\n\n# unzipping in the current folder\nunzip(zipF,exdir = \"./\")\n\nalarm_name = list.files(tools::file_path_sans_ext(downloaded_files))[1]\n\npath_to_file = paste0(tools::file_path_sans_ext(downloaded_files),\"/\",alarm_name,\"/\",alarm_name,\".csv\")\n\ndf = read.csv(path_to_file)\nhead(df)\n     CVP   PCWP  HIST    TPR     BP     CO HRBP HREK HRSA    PAP   SAO2   FIO2\n1 NORMAL NORMAL FALSE    LOW NORMAL   HIGH HIGH HIGH HIGH NORMAL NORMAL    LOW\n2 NORMAL NORMAL FALSE NORMAL    LOW    LOW HIGH HIGH HIGH NORMAL    LOW NORMAL\n3 NORMAL   HIGH FALSE NORMAL NORMAL   HIGH HIGH HIGH HIGH NORMAL    LOW NORMAL\n4 NORMAL NORMAL FALSE    LOW    LOW   HIGH HIGH HIGH HIGH NORMAL NORMAL NORMAL\n5 NORMAL NORMAL FALSE    LOW    LOW NORMAL HIGH HIGH HIGH NORMAL    LOW NORMAL\n6 NORMAL NORMAL FALSE    LOW NORMAL   HIGH HIGH HIGH HIGH NORMAL    LOW NORMAL\n    PRSS ECO2 MINV    MVS   HYP   LVF   APL  ANES   PMB    INT  KINK  DISC\n1   HIGH ZERO HIGH NORMAL FALSE FALSE FALSE FALSE FALSE NORMAL FALSE  TRUE\n2   HIGH ZERO ZERO NORMAL FALSE FALSE FALSE FALSE FALSE NORMAL FALSE FALSE\n3 NORMAL ZERO ZERO NORMAL FALSE FALSE FALSE FALSE FALSE NORMAL FALSE FALSE\n4   HIGH ZERO ZERO NORMAL FALSE FALSE FALSE FALSE FALSE NORMAL FALSE FALSE\n5    LOW ZERO ZERO NORMAL FALSE FALSE FALSE FALSE FALSE NORMAL FALSE FALSE\n6   HIGH HIGH ZERO NORMAL FALSE FALSE FALSE  TRUE FALSE NORMAL FALSE FALSE\n     LVV   STKV CCHL  ERLO   HR  ERCA   SHNT    PVS   ACO2 VALV VLNG VTUB\n1 NORMAL NORMAL HIGH FALSE HIGH FALSE NORMAL NORMAL NORMAL HIGH  LOW ZERO\n2 NORMAL    LOW HIGH FALSE HIGH FALSE NORMAL    LOW    LOW ZERO ZERO  LOW\n3 NORMAL NORMAL HIGH FALSE HIGH FALSE NORMAL    LOW    LOW ZERO ZERO  LOW\n4 NORMAL NORMAL HIGH FALSE HIGH FALSE NORMAL NORMAL    LOW ZERO ZERO  LOW\n5 NORMAL NORMAL HIGH FALSE HIGH FALSE NORMAL    LOW    LOW ZERO ZERO  LOW\n6 NORMAL NORMAL HIGH FALSE HIGH FALSE NORMAL    LOW    LOW ZERO ZERO  LOW\n    VMCH\n1 NORMAL\n2 NORMAL\n3 NORMAL\n4 NORMAL\n5 NORMAL\n6 NORMAL\nWe need to transform data first\nfor (item in colnames(df)){\n  df[,item] = as.factor(df[,item])\n}\ndata(\"alarm\")\nalarm_df &lt;- as.data.frame(na.omit(df))\n\np = length(names(alarm))\nn = dim(alarm)[1]\nfor (i in c(1:p)) {\n  alarm_df[,i]&lt;-as.numeric(alarm_df[,i])\n}\n\nApplying nonparanormal transformation to standardize the data.\nlibrary(\"huge\")\nalarm_df &lt;- huge.npn(alarm_df)\nConducting the nonparanormal (npn) transformation via shrunkun ECDF....done.\n#####\nDefining “true” graph as proposed for the ALARM dataset in\nbnlearn\n# \"True\" Graph ALARM\ndag_alarm = empty.graph(names(alarm))\nmodelstring(dag_alarm) = paste0(\"[HIST|LVF][CVP|LVV][PCWP|LVV][HYP][LVV|HYP:LVF]\",                    \"[LVF][STKV|HYP:LVF][ERLO][HRBP|ERLO:HR][HREK|ERCA:HR][ERCA][HRSA|ERCA:HR]\",\n\"[ANES][APL][TPR|APL][ECO2|ACO2:VLNG][KINK][MINV|INT:VLNG][FIO2]\",            \"[PVS|FIO2:VALV][SAO2|PVS:SHNT][PAP|PMB][PMB][SHNT|INT:PMB][INT]\",              \"[PRSS|INT:KINK:VTUB][DISC][MVS][VMCH|MVS][VTUB|DISC:VMCH]\",                    \"[VLNG|INT:KINK:VTUB][VALV|INT:VLNG][ACO2|VALV][CCHL|ACO2:ANES:SAO2:TPR]\",\n\"[HR|CCHL][CO|HR:STKV][BP|CO:TPR]\", sep = \"\")\n\nqgraph(dag_alarm, legend.cex = 0.3,\n       asize=2,edge.color=\"black\", vsize= 4)\n\nSelection of the set of nodes for subsetting\n### Subgraph \nsubgraph_nodes &lt;- c(\"INT\",\"VALV\",\"LVF\",\"LVV\",\"PCWP\",\"HR\",\"CCHL\",\"CVP\",\"HYP\",\"HRSA\",\"ERCA\")\nFirst procedure (bnlearns subgraph function). It is\nimplemented through a simple subsetting of the edges which are adjacent\nto the vertices contained in the subgraph_nodes set.\nprocedure1 &lt;- bnlearn::subgraph(dag_alarm, subgraph_nodes)\nqgraph(procedure1, legend.cex = 0.3,\n       asize=2,edge.color=\"black\", vsize= 5)\n\nSecond procedure selects the subgraph based on the\nfollowing euristics. Given the ground truth DAG \\(G=(V,E)\\) and subset of vertices \\(V_{s} \\subset V\\) the goal is to find the\ncorresponding set of vertices \\(E_{s}\\)\nsuch that for \\((V_s,E_s)\\) the\nstructure of the distribution for $ P_{V_s}$ does not contradict the\nstructure of the distribution \\(P_{V}\\)\nso that we the task of structure estimation (and then benchmarking) on\n\\((V_s,E_s)\\) can be done with a new\nground truth.\nLet \\(G = (V,E)\\) be the original\ndirected acyclic graph, and \\(P_{V}\\)\nis the joint distribution of random variables from \\(V\\).\nWe take two and check whether these vertices are \\(d-\\)connected given all others in \\(V_{s}\\). If they are not \\(d\\)-connected, there is no association (no\narrow in any direction). Otherwise, we have correlation (with unknown\ndirection). If one of the directions leads to the cycle in the original\ngraph, we resolve it and keep the other direction, otherwise we keep\nboth directions and then get the CPDAG.\nThird procedure which сreats the PAG for the\nobservable vertices in the subset-graph with respect to the latent\nvariables in the vertices set \\(V \\setminus\nV^{'}\\).\nPAG is the graph which is used to represent causal relationships in\nsituations where the exact underlying causal structure is not fully\nknown or observable. In our case we observe the variables in the set\n\\(V^{'}\\). Based on the covariance\nmatrix from the observed data in \\(V^{'}\\) we generate.\n######### Extract subgraph function\n\ncombn(subgraph_nodes, 2)[2,1]\n[1] \"VALV\"\ndim(combn(subgraph_nodes,2))[2]\n[1] 55\nextract_subgraph &lt;- function(dag, nodes){\n  sg &lt;- bnlearn::subgraph(dag,nodes) # procedure 1 (to be discussed)\n  combinations &lt;- combn(nodes,2) # all combinations of 2 distinct nodes in \"nodes\"\n  n &lt;- dim(combinations)[2]\n  for (i in 1:n){\n    observed &lt;- nodes[nodes!=combinations[1,i] & nodes!=combinations[2,i]] # V'\\{v,w}\n    if (!is.element(combinations[1,i], nbr(sg, combinations[2,i])) & # check if there exists an edge already\n        !bnlearn::dsep(dag,combinations[1,i],combinations[2,i])){ ### check if d-connected\n      sg &lt;- set.edge(sg, from = combinations[1,i], to = combinations[2,i]) ### undirected edge in case d-connected\n    }\n  }\n  return(cpdag(sg)) ### to be discussed: return(cpdag(sg))\n}\n\nprocedure2 &lt;- extract_subgraph(dag_alarm, subgraph_nodes)\nqgraph(procedure2, legend.cex = 0.3,\n       asize=2,edge.color=\"black\", vsize= 5)\n\nSubsetting the dataset according to “subgraph_nodes” selection\nalarm_dfSubset &lt;-as.data.frame(alarm_df[,subgraph_nodes])\nCompute Skeleton\n================\nOrder=0; remaining edges:110\nx= 1  y= 2  S=  : pval = 0.005042832 \nx= 1  y= 3  S=  : pval = 0.9641842 \nx= 1  y= 4  S=  : pval = 0.9723853 \nx= 1  y= 5  S=  : pval = 0.8775183 \nx= 1  y= 6  S=  : pval = 0.907297 \nx= 1  y= 7  S=  : pval = 0.9959888 \nx= 1  y= 8  S=  : pval = 0.9683535 \nx= 1  y= 9  S=  : pval = 0.9685349 \nx= 1  y= 10  S=  : pval = 0.8589276 \nx= 1  y= 11  S=  : pval = 0.9653777 \nx= 2  y= 1  S=  : pval = 0.005042832 \nx= 2  y= 3  S=  : pval = 0.9282327 \nx= 2  y= 4  S=  : pval = 0.7629024 \nx= 2  y= 5  S=  : pval = 0.7853056 \nx= 2  y= 6  S=  : pval = 0.08205837 \nx= 2  y= 7  S=  : pval = 0.03096158 \nx= 2  y= 8  S=  : pval = 0.6245208 \nx= 2  y= 9  S=  : pval = 0.6906646 \nx= 2  y= 10  S=  : pval = 0.4197323 \nx= 2  y= 11  S=  : pval = 0.8553025 \nx= 3  y= 4  S=  : pval = 6.13956e-10 \nx= 3  y= 5  S=  : pval = 3.094505e-08 \nx= 3  y= 6  S=  : pval = 0.9763708 \nx= 3  y= 7  S=  : pval = 0.8158414 \nx= 3  y= 8  S=  : pval = 2.009214e-12 \nx= 3  y= 9  S=  : pval = 0.8672087 \nx= 3  y= 10  S=  : pval = 0.9411474 \nx= 3  y= 11  S=  : pval = 0.9146438 \nx= 4  y= 3  S=  : pval = 6.13956e-10 \nx= 4  y= 5  S=  : pval = 0 \nx= 4  y= 6  S=  : pval = 0.9792193 \nx= 4  y= 7  S=  : pval = 0.9291572 \nx= 4  y= 8  S=  : pval = 2.726448e-225 \nx= 4  y= 9  S=  : pval = 4.528775e-213 \nx= 4  y= 10  S=  : pval = 0.9612071 \nx= 4  y= 11  S=  : pval = 0.9630885 \nx= 5  y= 3  S=  : pval = 3.094505e-08 \nx= 5  y= 4  S=  : pval = 0 \nx= 5  y= 6  S=  : pval = 0.9588945 \nx= 5  y= 7  S=  : pval = 0.8678652 \nx= 5  y= 8  S=  : pval = 4.026479e-171 \nx= 5  y= 9  S=  : pval = 3.497935e-165 \nx= 5  y= 10  S=  : pval = 0.9452638 \nx= 5  y= 11  S=  : pval = 0.9494562 \nx= 6  y= 7  S=  : pval = 1.246392e-251 \nx= 6  y= 8  S=  : pval = 0.9173549 \nx= 6  y= 9  S=  : pval = 0.9585462 \nx= 6  y= 10  S=  : pval = 7.873739e-103 \nx= 6  y= 11  S=  : pval = 0.9979575 \nx= 7  y= 2  S=  : pval = 0.03096158 \nx= 7  y= 6  S=  : pval = 1.246392e-251 \nx= 7  y= 8  S=  : pval = 0.993056 \nx= 7  y= 9  S=  : pval = 0.950604 \nx= 7  y= 10  S=  : pval = 7.565883e-58 \nx= 7  y= 11  S=  : pval = 0.8395238 \nx= 8  y= 3  S=  : pval = 2.009214e-12 \nx= 8  y= 4  S=  : pval = 2.726448e-225 \nx= 8  y= 5  S=  : pval = 4.026479e-171 \nx= 8  y= 9  S=  : pval = 1.342408e-84 \nx= 8  y= 10  S=  : pval = 0.8599433 \nx= 8  y= 11  S=  : pval = 0.7198062 \nx= 9  y= 4  S=  : pval = 4.528775e-213 \nx= 9  y= 5  S=  : pval = 3.497935e-165 \nx= 9  y= 8  S=  : pval = 1.342408e-84 \nx= 9  y= 10  S=  : pval = 0.8939413 \nx= 9  y= 11  S=  : pval = 0.8962443 \nx= 10  y= 6  S=  : pval = 7.873739e-103 \nx= 10  y= 7  S=  : pval = 7.565883e-58 \n|i= 100 |iMax= 110 \nx= 10  y= 11  S=  : pval = 1.755557e-93 \nx= 11  y= 10  S=  : pval = 1.755557e-93 \nOrder=1; remaining edges:30\nx= 2  y= 1  S= 7 : pval = 0.00495715 \nx= 2  y= 7  S= 1 : pval = 0.03035172 \nx= 3  y= 4  S= 5 : pval = 0.005480407 \nx= 3  y= 4  S= 8 : pval = 0.2028018 \nx= 3  y= 5  S= 4 : pval = 0.6811937 \nx= 3  y= 8  S= 4 : pval = 0.0003707107 \nx= 3  y= 8  S= 5 : pval = 1.097774e-05 \nx= 4  y= 5  S= 3 : pval = 0 \nx= 4  y= 5  S= 8 : pval = 0 \nx= 4  y= 5  S= 9 : pval = 0 \nx= 4  y= 8  S= 3 : pval = 1.133435e-214 \nx= 4  y= 8  S= 5 : pval = 1.911786e-45 \nx= 4  y= 8  S= 9 : pval = 4.792264e-129 \nx= 4  y= 9  S= 3 : pval = 3.572456e-229 \nx= 4  y= 9  S= 5 : pval = 1.206858e-40 \nx= 4  y= 9  S= 8 : pval = 4.570084e-118 \nx= 5  y= 4  S= 3 : pval = 0 \nx= 5  y= 4  S= 8 : pval = 0 \nx= 5  y= 4  S= 9 : pval = 0 \nx= 5  y= 8  S= 3 : pval = 6.416106e-163 \nx= 5  y= 8  S= 4 : pval = 0.97089 \nx= 5  y= 9  S= 3 : pval = 6.32675e-174 \nx= 5  y= 9  S= 4 : pval = 0.7334259 \nx= 6  y= 7  S= 10 : pval = 3.03145e-181 \nx= 6  y= 10  S= 7 : pval = 2.498684e-43 \nx= 7  y= 2  S= 6 : pval = 0.2015305 \nx= 7  y= 6  S= 2 : pval = 1.718556e-250 \nx= 7  y= 6  S= 10 : pval = 3.03145e-181 \nx= 7  y= 10  S= 2 : pval = 1.192355e-57 \nx= 7  y= 10  S= 6 : pval = 0.9773594 \nx= 8  y= 3  S= 4 : pval = 0.0003707107 \nx= 8  y= 3  S= 5 : pval = 1.097774e-05 \nx= 8  y= 3  S= 9 : pval = 8.523627e-18 \nx= 8  y= 4  S= 3 : pval = 1.133435e-214 \nx= 8  y= 4  S= 5 : pval = 1.911786e-45 \nx= 8  y= 4  S= 9 : pval = 4.792264e-129 \nx= 8  y= 9  S= 3 : pval = 2.178566e-90 \nx= 8  y= 9  S= 4 : pval = 0.01885697 \nx= 8  y= 9  S= 5 : pval = 0.0007682433 \nx= 9  y= 4  S= 5 : pval = 1.206858e-40 \nx= 9  y= 4  S= 8 : pval = 4.570084e-118 \nx= 9  y= 8  S= 4 : pval = 0.01885697 \nx= 9  y= 8  S= 5 : pval = 0.0007682433 \nx= 10  y= 6  S= 7 : pval = 2.498684e-43 \nx= 10  y= 6  S= 11 : pval = 2.283733e-182 \nx= 10  y= 11  S= 6 : pval = 4.036619e-172 \nx= 10  y= 11  S= 7 : pval = 3.095705e-132 \nOrder=2; remaining edges:18\nx= 4  y= 5  S= 8 9 : pval = 1.018631e-222 \nx= 4  y= 8  S= 5 9 : pval = 4.666987e-44 \nx= 4  y= 9  S= 5 8 : pval = 2.859149e-39 \nx= 8  y= 3  S= 4 9 : pval = 0.001962647 \nx= 8  y= 4  S= 3 9 : pval = 1.019198e-112 \nx= 8  y= 9  S= 3 4 : pval = 0.118346 \n\nCompute PDSEP\n=============\n\nCompute collider:\n\n 6 *-&gt; 10 &lt;-* 11 \n\n 11 *-&gt; 10 &lt;-* 6 \n\nPossible D-Sep of 1 is: 2 \n\ny =   2\n.........\n\nPossible D-Sep of 2 is: 1 \n\ny =   1\n.........\n\nPossible D-Sep of 3 is: 8 \n\ny =   8\n.........\n\nPossible D-Sep of 4 is: 5 8 9 \n\ny =   5\n.........\n\ny =   8\n.........\n\ny =   9\n.........\n\nPossible D-Sep of 5 is: 4 \n\ny =   4\n.........\n\nPossible D-Sep of 6 is: 7 10 11 \n\ny =   7\n.........\nord =  1 \nord =  2 \n\ny =  10\n.........\nord =  1 \nord =  2 \n\nPossible D-Sep of 7 is: 6 \n\ny =   6\n.........\n\nPossible D-Sep of 8 is: 3 4 \n\ny =   3\n.........\n\ny =   4\n.........\n\nPossible D-Sep of 9 is: 4 \n\ny =   4\n.........\n\nPossible D-Sep of 10 is: 6 11 \n\ny =   6\n.........\n\ny =  11\n.........\n\nPossible D-Sep of 11 is: 6 10 \n\ny =  10\n.........\nord =  1 \n\nDirect edges:\n=============\nUsing rules: 1 2 3 4 5 6 7 8 9 10 \nCompute collider:\n\n 6 *-&gt; 10 &lt;-* 11 \nSxz= and Szx=  \n\n 11 *-&gt; 10 &lt;-* 6 \nSxz=  and Szx= \nLoading required namespace: Rgraphviz\nWarning in .local(x, y, ...): main title cannot *not* be set yet\n[Rgraphviz::plot() deficiency]\n\nApplying constraint-based algorithms\nRes_stable=pc.stable(alarm_dfSubset)\n\nRes_iamb=iamb(alarm_dfSubset)\n\nRes_gs=gs(alarm_dfSubset)\n\nRes_fiamb=fast.iamb(alarm_dfSubset)\n\nRes_mmpc=mmpc(alarm_dfSubset)\nApplying score-based algorithms\nRes_hc = hc(alarm_dfSubset)\nRes_tabu = tabu(alarm_dfSubset)\nVisualize resulting subgraph in the images below:\npar(mfrow=c(2, 4), mar=c(1, 1, 1, 1), oma=c(2, 2, 2, 2))\n\n\nig_proc1 &lt;- as.igraph(procedure1)\nig_proc2 &lt;- as.igraph(procedure2)\nig_pc &lt;- as.igraph(Res_stable)\nig_iamb &lt;- as.igraph(Res_iamb)\nig_gs &lt;- as.igraph(Res_gs)\nig_fiamb &lt;- as.igraph(Res_fiamb)\nig_mmpc &lt;- as.igraph(Res_mmpc)\n\nig_hc &lt;- as.igraph(Res_hc)\nig_tabu &lt;- as.igraph(Res_tabu)\n\nplot(ig_proc1, main = \"proc1\", frame = T, layout=layout_with_fr, vertex.size=18,\n     vertex.label.dist=4, vertex.color=\"red\", edge.arrow.size=0.4, vertex.label.cex=1)\nplot(ig_proc2, main = \"proc2\", frame = T, layout=layout_with_fr, vertex.size=18,\n     vertex.label.dist=4, vertex.color=\"red\", edge.arrow.size=0.4, vertex.label.cex=1)\nplot(ig_pc, main = \"pc\", frame = T, layout=layout_with_fr, vertex.size=18,\n     vertex.label.dist=4, vertex.color=\"red\", edge.arrow.size=0.4, vertex.label.cex=1)\nplot(ig_iamb, main = \"iamb\", frame = T, layout=layout_with_fr, vertex.size=18,\n     vertex.label.dist=4, vertex.color=\"red\", edge.arrow.size=0.4, vertex.label.cex=1)\nplot(ig_gs, main = \"gs\", frame = T, layout=layout_with_fr, vertex.size=18,\n     vertex.label.dist=4, vertex.color=\"red\", edge.arrow.size=0.4, vertex.label.cex=1)\nplot(ig_fiamb, main = \"fiamb\", frame = T, layout=layout_with_fr, vertex.size=18,\n     vertex.label.dist=4, vertex.color=\"red\", edge.arrow.size=0.4, vertex.label.cex=1)\nplot(ig_mmpc, main = \"mmpc\", frame = T, layout=layout_with_fr, vertex.size=18,\n     vertex.label.dist=4, vertex.color=\"red\", edge.arrow.size=0.4, vertex.label.cex=1)\nplot(ig_hc, main = \"hc\", frame = T, layout=layout_with_fr, vertex.size=18,\n     vertex.label.dist=4, vertex.color=\"red\", edge.arrow.size=0.4, vertex.label.cex=1)\nplot(ig_tabu, main = \"tabu\", frame = T, layout=layout_with_fr, vertex.size=18,\n     vertex.label.dist=4, vertex.color=\"red\", edge.arrow.size=0.4, vertex.label.cex=1)\n\nSelfdefined function for different measures\nmeasure = function(estim, true){\n  result &lt;- matrix(1,4)\n  com &lt;- bnlearn::compare(estim, true)\n  shd &lt;- bnlearn::shd(estim,true)\n  result[1,] &lt;- com$tp\n  result[2,] &lt;- com$fp\n  result[3,] &lt;- com$fn\n  result[4,] &lt;- shd\n  rownames(result) &lt;- c(\"true positives\",\"false positives\",\"false negatives\",\"structural hamming distance\")\n  colnames(result) &lt;- deparse(substitute(estim))\n  return(result)\n}\nMetric evaluation for procedure 1\nmeasure(Res_stable, procedure1)\n                            Res_stable\ntrue positives                       6\nfalse positives                      2\nfalse negatives                      5\nstructural hamming distance          5\nmeasure(Res_iamb, procedure1)\n                            Res_iamb\ntrue positives                     5\nfalse positives                    3\nfalse negatives                    6\nstructural hamming distance        4\nmeasure(Res_gs, procedure1)\n                            Res_gs\ntrue positives                   5\nfalse positives                  3\nfalse negatives                  6\nstructural hamming distance      4\nmeasure(Res_fiamb, procedure1)\n                            Res_fiamb\ntrue positives                      5\nfalse positives                     3\nfalse negatives                     6\nstructural hamming distance         4\nmeasure(Res_mmpc, procedure1)\n                            Res_mmpc\ntrue positives                     0\nfalse positives                    8\nfalse negatives                   11\nstructural hamming distance        9\nmeasure(Res_hc, procedure1)\n                            Res_hc\ntrue positives                   5\nfalse positives                  3\nfalse negatives                  7\nstructural hamming distance      9\nmeasure(Res_tabu, procedure1)\n                            Res_tabu\ntrue positives                     5\nfalse positives                    3\nfalse negatives                    7\nstructural hamming distance        9\nMetric evaluation for procedure 2\nmeasure(Res_stable, procedure2)\n                            Res_stable\ntrue positives                       4\nfalse positives                     16\nfalse negatives                      7\nstructural hamming distance         16\nmeasure(Res_iamb, procedure2)\n                            Res_iamb\ntrue positives                     6\nfalse positives                   14\nfalse negatives                    5\nstructural hamming distance       14\nmeasure(Res_gs, procedure2)\n                            Res_gs\ntrue positives                   6\nfalse positives                 14\nfalse negatives                  5\nstructural hamming distance     14\nmeasure(Res_fiamb, procedure2)\n                            Res_fiamb\ntrue positives                      6\nfalse positives                    14\nfalse negatives                     5\nstructural hamming distance        14\nmeasure(Res_mmpc, procedure2)\n                            Res_mmpc\ntrue positives                     4\nfalse positives                   16\nfalse negatives                    7\nstructural hamming distance       16\nmeasure(Res_hc, procedure2)\n                            Res_hc\ntrue positives                   3\nfalse positives                 17\nfalse negatives                  9\nstructural hamming distance     17\nmeasure(Res_tabu, procedure2)\n                            Res_tabu\ntrue positives                     5\nfalse positives                   15\nfalse negatives                    7\nstructural hamming distance       17",
    "crumbs": [
      "Accompanying Statistical Notebooks",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>ALARM Subgraph Notebook</span>"
    ]
  },
  {
    "objectID": "gallery/notebook4.html",
    "href": "gallery/notebook4.html",
    "title": "6  Cause-Effect Pairs MPI Tuebingen",
    "section": "",
    "text": "file1644b533d21c2.knit\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDescription of the dataset\nThe Tuebingen cause-effect dataset contains the 108 datasets, every\nwith 2 variables. The description of the data is the following:\nthe data represented here is a growing database with different data\nfor testing causal detection algorithms. The goal here is to distinguish\nbetween cause and effect. We searched for data sets with known ground\ntruth. However, we do not guarantee that all provided ground truths are\ncorrect. The datafiles are .txt-files and contain two variables, one is\nthe cause and the other the effect. For every example there exists a\ndescription file where you can find the ground truth and how the data\nwas derived.\nNote that not always the first column is the cause and the second the\neffect. This is indicated in a meta-data file. There is also a weighting\nfactor suggested for some pairs which are very similar if you want to\ncalculate the overall performance.\nSetup of the problem We have 89 datasets\nwith variables\nVar1, Var2. The goal\nis to establish cause-effect relationships between 2 variables using the\ndata.\n### loading packages\nlibrary(\"liver\")\nlibrary(\"qgraph\")\nlibrary(\"igraph\")\nlibrary(\"bnlearn\")\nlibrary(\"dplyr\")\n\nlist_of_datasets = read.csv(\"whitelist.csv\")\nLoading the Tuebingen datasets\nwhitelist = as.list(list_of_datasets)\nhead(list_of_datasets)\n##   whitelist\n## 1         1\n## 2         2\n## 3         3\n## 4         4\n## 5         5\n## 6         6\n# randomly pick 5 datasets for study comparison \nselected = list_of_datasets[sample(nrow(list_of_datasets),5),]\nprint(selected)\n## [1] 34 50 61 64  9\nHere we taking a glimpse in the tubingen data\n# here we extract the selected datasets to perform benchmarking\n\nsel_to_str = as.character(selected)\nelem_len= nchar(sel_to_str)\nTranscribing the lengths of the array to form the file\nnames\nresult = vector(mode=\"character\", length=5)\nfor (i in 1:5){\n  text_int = \"causal_tubingen\"\n  elem_len = nchar(sel_to_str[i])\n  result[i] &lt;- switch(elem_len,\n       \"1\" = paste(text_int,\"00\",sel_to_str[i],sep = \"\"),\n       \"2\" = paste(text_int,\"0\",sel_to_str[i],sep = \"\"),\n       \"3\" = paste(text_int,\"\",sel_to_str[i],sep = \"\"),\n)\n}\nlibrary(ggplot2)\n\nset.seed(1)\n\n# The data used can be obtained from https://webdav.tuebingen.mpg.de/cause-effect/. Here we collect automatically the names and descriptions. \nfilenames &lt;- sprintf(\"https://webdav.tuebingen.mpg.de/cause-effect/pair%04d.txt\", seq(1, 108, 1))\ndescriptions &lt;- sprintf(\"https://webdav.tuebingen.mpg.de/cause-effect/pair%04d_des.txt\", seq(1, 108, 1))\nWe are considering the datasets which have 2 variables: in the\nfollowing we use the HSIC criterion to test for independence of the\nresiduals and covariates\nlibrary(\"utils\")\n\nresults &lt;- data.frame(matrix(nrow = 0, ncol = 2))\ncolnames(results) &lt;- c(\"pair\", \"HSIC test\")\n\n# dropping the datasets due to \ndrop_f = c(17,64:68)\np_val = 0.05\nlibrary(krr)\nlibrary(dHSIC)\nn = 100 \n\nfor (i in setdiff(whitelist$whitelist,drop_f)) {\n  # Ground truth files\n\n  if (i %in% c(86, 88)) {\n    expected = c(1, 2)\n  } else {\n    description_file  = url(sprintf(\"https://webdav.tuebingen.mpg.de/cause-effect/pair%04d_des.txt\", 1))\n    # Pair 86: x to y, 88 x to y\n    description1 = paste(readLines(description_file), collapse=\" \")\n    description1 = gsub(\" \", \"\", description1)\n    if (grepl(\"&gt;[Yy]|[Yy]&lt;\", description1)) {\n      expected = c(1, 2)\n    } else if (grepl(\"&gt;[Xx]|[Xx]&lt;\", description1)) {\n      expected = c(2, 1)\n    } else {\n      print(\"This shouldn't happen\")\n    }\n    # print(expected)\n  }\n  \n  # data_file &lt;- url(sprintf(\"https://webdav.tuebingen.mpg.de/cause-effect/pair%04d.txt\", i))\n    cause_effect_pair = read.table(filenames[i], header=F)\n    cause_effect_pair = as.data.frame(as.matrix(cause_effect_pair[1:min(nrow(cause_effect_pair),n),]))\n    var1  = as.matrix(cause_effect_pair[,1])\n    var2  = as.matrix(cause_effect_pair[,2])\n    # LiNGAM\n    # Residual analysis based on HSIC test\n    \n    # Fit the ridge regression model\n    fit_1 = krr(var1, var2, sigma = 1, lambda = 1)\n    #predict_1 =  predict(fit_1, xnew =x1_seq )\n\n    fit_2 = krr(var2, var1, sigma = 1, lambda = 1)\n    #predict_2 = predict(fit_2,xnew  = x2_seq)\n    \n    # Calculate the residuals\n    residuals_1 = residuals(fit_1, type = \"deviance\")\n    residuals_2 = residuals(fit_2, type = \"deviance\")\n    \n    \n    hsic_12 = dhsic.test(residuals_1,var1)\n    hsic_21 = dhsic.test(residuals_2,var2)\n    \n   #  print(sprintf(\"Pair%04d\",i))\n   #  print(hsic_12$p.value)\n   #  print(hsic_21$p.value)\n    \n    if (hsic_12$p.value&lt;hsic_21$p.value){\n      result = c(1,2)\n    }\n    else if (hsic_21$p.value&lt;hsic_12$p.value){\n      result = c(2,1)\n    }\n    else {\n      result = c(1,2)\n    }\n    # Results\n    results[nrow(results) + 1,] &lt;- c(i, all(expected == result))\n}\nRefererences\n\\[1\\] Pfister, N, and Peter, J,.\nIndependence Testing via Hilbert Schmidt Independence Criterion. https://doi.org/10.1111/rssb.12235\n\\[2\\] https://vulstats.ucsd.edu/chi-squared.html\n\\[3\\] A. Gretton, K. Fukumizu, C.\nH. Teo, L. Song, B. Sch’’olkopf, and A. Smola. A kernel statistical test\nof independence. In Advances in Neural Information Processing Systems 20\n(NIPS), 2008. SBN: 978-1-60560-949-2\n\\[4\\] Peters, J., Mooij, J.M.,\nJanzing, D. and Sch”olkopf, B., 2014. Causal discovery with continuous\nadditive noise models. JMLR 15(58):2009−2053, 2014.",
    "crumbs": [
      "Accompanying Statistical Notebooks",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Cause-Effect Pairs MPI Tuebingen</span>"
    ]
  },
  {
    "objectID": "gallery/notebook5.html",
    "href": "gallery/notebook5.html",
    "title": "7  online html",
    "section": "",
    "text": "This page is a direct inclusion of a .html file from git.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlarm dataset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlarm dataset\nOleksandr Zadorozhnyi\n\n\n\n\nSetup of the problem \nIn the context of graphical modeling and structure learning from data\nwe consider a simple task of determining the most appropriate graphical\nstructure for a Bayesian network model (DAG estimation) based on the\navailable data. This problem is fundamental in probabilistic graphical\nmodeling, and it involves identifying the conditional dependencies\nbetween variables in the dataset, which are represented by edges (arcs)\nin the Bayesian network.\nIn this notebook we perform a simple experiment to estimate the\nstructure between the covariates from the (subset) of dataset\n“alarm”.\nLoading the required libraries.\nlibrary(bnlearn)\nlibrary(qgraph)\nlibrary(\"huge\")\nlibrary(ggplot2)\nlibrary(tidyverse)\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.4     ✔ tibble    3.2.1\n✔ purrr     1.0.4     ✔ tidyr     1.3.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\nLoading the data from Zenodo collection/community:\n# necessary libraries to use for Zenodo REST-API\nlibrary(zen4R)\n\nzenodo &lt;- ZenodoManager$new(\n  logger = \"INFO\" # use \"DEBUG\" to see detailed API operation logs, use NULL if you don't want logs at all\n)\n\n# downloading files using zenodo doi and reading from the file \nrec1 &lt;- zenodo$getRecordByDOI(\"10.5281/zenodo.7676616\")\n[zen4R][INFO] ZenodoRequest - Fetching https://zenodo.org/api/records?q=doi:%2210.5281/zenodo.7676616%22&size=10&page=1&allversions=1 \nℹ Successfully fetched list of published records - page 1\n[zen4R][INFO] ZenodoManager - Successfully fetched list of published records - page 1 \n✔ Successfully fetched list of published records!\n[zen4R][INFO] ZenodoManager - Successfully fetched list of published records! \n✔ Successfully fetched record for DOI '10.5281/zenodo.7676616'!\n[zen4R][INFO] ZenodoManager - Successfully fetched record for DOI '10.5281/zenodo.7676616'! \nfiles &lt;- rec1$listFiles(pretty = TRUE)\n\n#create a folder where to download files from record\ndir.create(\"download_zenodo\")\nWarning in dir.create(\"download_zenodo\"): 'download_zenodo' already exists\n#download files\nrec1$downloadFiles(path = \"download_zenodo\")\nℹ Download in sequential mode\n[zen4R][INFO] ZenodoRecord - Download in sequential mode \nℹ Will download 1 file from record '7676616' (doi: '10.5281/zenodo.7676616') - total size: 2 MiB\n[zen4R][INFO] ZenodoRecord - Will download 1 file from record '7676616' (doi: '10.5281/zenodo.7676616') - total size: 2 MiB \nℹ Downloading file 'bnlearn_data.zip' - size: 2 MiB\n[zen4R][INFO] Downloading file 'bnlearn_data.zip' - size: 2 MiB\nℹ File downloaded at '/Users/mareis/Documents/projects/MaRDI/StMaRDI/website/GMCI_MaRDI/gallery/download_zenodo'.\n[zen4R][INFO] File downloaded at '/Users/mareis/Documents/projects/MaRDI/StMaRDI/website/GMCI_MaRDI/gallery/download_zenodo'.\nℹ Verifying file integrity...\n[zen4R][INFO] ZenodoRecord - Verifying file integrity... \nℹ File 'bnlearn_data.zip': integrity verified (md5sum: f123ea701227cfd8a43996183b7c5279)\n[zen4R][INFO] File 'bnlearn_data.zip': integrity verified (md5sum: f123ea701227cfd8a43996183b7c5279)\n✔ End of download\n[zen4R][INFO] ZenodoRecord - End of download \ndownloaded_files &lt;- list.files(\"download_zenodo\")\n\nzipF = sprintf(\"download_zenodo/%s\",downloaded_files)\n\n# unzipping in the current folder\nunzip(zipF,exdir = \"./\")\n\nalarm_name = list.files(tools::file_path_sans_ext(downloaded_files))[1]\n\npath_to_file = paste0(tools::file_path_sans_ext(downloaded_files),\"/\",alarm_name,\"/\",alarm_name,\".csv\")\n\ndf = read.csv(path_to_file)\nhead(df)\n     CVP   PCWP  HIST    TPR     BP     CO HRBP HREK HRSA    PAP   SAO2   FIO2\n1 NORMAL NORMAL FALSE    LOW NORMAL   HIGH HIGH HIGH HIGH NORMAL NORMAL    LOW\n2 NORMAL NORMAL FALSE NORMAL    LOW    LOW HIGH HIGH HIGH NORMAL    LOW NORMAL\n3 NORMAL   HIGH FALSE NORMAL NORMAL   HIGH HIGH HIGH HIGH NORMAL    LOW NORMAL\n4 NORMAL NORMAL FALSE    LOW    LOW   HIGH HIGH HIGH HIGH NORMAL NORMAL NORMAL\n5 NORMAL NORMAL FALSE    LOW    LOW NORMAL HIGH HIGH HIGH NORMAL    LOW NORMAL\n6 NORMAL NORMAL FALSE    LOW NORMAL   HIGH HIGH HIGH HIGH NORMAL    LOW NORMAL\n    PRSS ECO2 MINV    MVS   HYP   LVF   APL  ANES   PMB    INT  KINK  DISC\n1   HIGH ZERO HIGH NORMAL FALSE FALSE FALSE FALSE FALSE NORMAL FALSE  TRUE\n2   HIGH ZERO ZERO NORMAL FALSE FALSE FALSE FALSE FALSE NORMAL FALSE FALSE\n3 NORMAL ZERO ZERO NORMAL FALSE FALSE FALSE FALSE FALSE NORMAL FALSE FALSE\n4   HIGH ZERO ZERO NORMAL FALSE FALSE FALSE FALSE FALSE NORMAL FALSE FALSE\n5    LOW ZERO ZERO NORMAL FALSE FALSE FALSE FALSE FALSE NORMAL FALSE FALSE\n6   HIGH HIGH ZERO NORMAL FALSE FALSE FALSE  TRUE FALSE NORMAL FALSE FALSE\n     LVV   STKV CCHL  ERLO   HR  ERCA   SHNT    PVS   ACO2 VALV VLNG VTUB\n1 NORMAL NORMAL HIGH FALSE HIGH FALSE NORMAL NORMAL NORMAL HIGH  LOW ZERO\n2 NORMAL    LOW HIGH FALSE HIGH FALSE NORMAL    LOW    LOW ZERO ZERO  LOW\n3 NORMAL NORMAL HIGH FALSE HIGH FALSE NORMAL    LOW    LOW ZERO ZERO  LOW\n4 NORMAL NORMAL HIGH FALSE HIGH FALSE NORMAL NORMAL    LOW ZERO ZERO  LOW\n5 NORMAL NORMAL HIGH FALSE HIGH FALSE NORMAL    LOW    LOW ZERO ZERO  LOW\n6 NORMAL NORMAL HIGH FALSE HIGH FALSE NORMAL    LOW    LOW ZERO ZERO  LOW\n    VMCH\n1 NORMAL\n2 NORMAL\n3 NORMAL\n4 NORMAL\n5 NORMAL\n6 NORMAL\nWe need to transform data first\nfor (item in colnames(df)){\n  df[,item] = as.factor(df[,item])\n}\nDescription of the data.\nThe ALARM (“A Logical Alarm Reduction Mechanism”) is a Bayesian\nnetwork designed to provide an alarm message system for patient\nmonitoring.\nThe alarm data set contains the following 37 variables\n:\nCVP (central venous pressure): a three-level factor with levels LOW, NORMAL and HIGH.\n\nPCWP (pulmonary capillary wedge pressure): a three-level factor with levels LOW, NORMAL and HIGH.\n\nHIST (history): a two-level factor with levels TRUE and FALSE.\n\nTPR (total peripheral resistance): a three-level factor with levels LOW, NORMAL and HIGH.\n\nBP (blood pressure): a three-level factor with levels LOW, NORMAL and HIGH.\n\nCO (cardiac output): a three-level factor with levels LOW, NORMAL and HIGH.\n\nHRBP (heart rate / blood pressure): a three-level factor with levels LOW, NORMAL and HIGH.\n\nHREK (heart rate measured by an EKG monitor): a three-level factor with levels LOW, NORMAL and HIGH.\n\nHRSA (heart rate / oxygen saturation): a three-level factor with levels LOW, NORMAL and HIGH.\n\nPAP (pulmonary artery pressure): a three-level factor with levels LOW, NORMAL and HIGH.\n\nSAO2 (arterial oxygen saturation): a three-level factor with levels LOW, NORMAL and HIGH.\n\nFIO2 (fraction of inspired oxygen): a two-level factor with levels LOW and NORMAL.\n\nPRSS (breathing pressure): a four-level factor with levels ZERO, LOW, NORMAL and HIGH.\n\nECO2 (expelled CO2): a four-level factor with levels ZERO, LOW, NORMAL and HIGH.\n\nMINV (minimum volume): a four-level factor with levels ZERO, LOW, NORMAL and HIGH.\n\nMVS (minimum volume set): a three-level factor with levels LOW, NORMAL and HIGH.\n\nHYP (hypovolemia): a two-level factor with levels TRUE and FALSE.\n\nLVF (left ventricular failure): a two-level factor with levels TRUE and FALSE.\n\nAPL (anaphylaxis): a two-level factor with levels TRUE and FALSE.\n\nANES (insufficient anesthesia/analgesia): a two-level factor with levels TRUE and FALSE.\n\nPMB (pulmonary embolus): a two-level factor with levels TRUE and FALSE.\n\nINT (intubation): a three-level factor with levels NORMAL, ESOPHAGEAL and ONESIDED.\n\nKINK (kinked tube): a two-level factor with levels TRUE and FALSE.\n\nDISC (disconnection): a two-level factor with levels TRUE and FALSE.\n\nLVV (left ventricular end-diastolic volume): a three-level factor with levels LOW, NORMAL and HIGH.\n\nSTKV (stroke volume): a three-level factor with levels LOW, NORMAL and HIGH.\n\nCCHL (catecholamine): a two-level factor with levels NORMAL and HIGH.\n\nERLO (error low output): a two-level factor with levels TRUE and FALSE.\n\nHR (heart rate): a three-level factor with levels LOW, NORMAL and HIGH.\n\nERCA (electrocauter): a two-level factor with levels TRUE and FALSE.\n\nSHNT (shunt): a two-level factor with levels NORMAL and HIGH.\n\nPVS (pulmonary venous oxygen saturation): a three-level factor with levels LOW, NORMAL and HIGH.\n\nACO2 (arterial CO2): a three-level factor with levels LOW, NORMAL and HIGH.\n\nVALV (pulmonary alveoli ventilation): a four-level factor with levels ZERO, LOW, NORMAL and HIGH.\n\nVLNG (lung ventilation): a four-level factor with levels ZERO, LOW, NORMAL and HIGH.\n\nVTUB (ventilation tube): a four-level factor with levels ZERO, LOW, NORMAL and HIGH.\n\nVMCH (ventilation machine): a four-level factor with levels ZERO, LOW, NORMAL and HIGH.\nTransforming the data to decode the categorical values as\nintegers.\nalarm_df &lt;- as.data.frame(na.omit(df))\n\np = length(names(df))\nn = dim(df)[1]\n for (i in c(1:p)) {\n     alarm_df[,i]&lt;-as.numeric(alarm_df[,i])\n}\nApplying nonparanormal transformation to standardize the data. More\nprecisely it transforms the data using the truncated empirical\nprobability distribution function and the final re-normalization.\nselection &lt;- c(\"TPR\",\"PMB\",\"VTUB\",\"VLNG\",\"CO\")\n\n\n#alarm_df &lt;- huge.npn(alarm_df)\nalarm_df_npn = huge.npn(alarm_df)\nConducting the nonparanormal (npn) transformation via shrunkun ECDF....done.\nhead(alarm_df_npn)\n        CVP       PCWP        HIST        TPR        BP         CO       HRBP\n1 0.5073642  0.6137092 -0.09973971 -0.1768279 1.7013279 -0.8713625 -0.6646985\n2 0.5073642  0.6137092 -0.09973971  1.2401612 0.2199787  0.5248706 -0.6646985\n3 0.5073642 -1.8179024 -0.09973971  1.2401612 1.7013279 -0.8713625 -0.6646985\n4 0.5073642  0.6137092 -0.09973971 -0.1768279 0.2199787 -0.8713625 -0.6646985\n5 0.5073642  0.6137092 -0.09973971 -0.1768279 0.2199787  1.6119505 -0.6646985\n6 0.5073642  0.6137092 -0.09973971 -0.1768279 1.7013279 -0.8713625 -0.6646985\n        HREK       HRSA       PAP      SAO2        FIO2       PRSS      ECO2\n1 -0.7062245 -0.7035549 0.1981972 3.1144053 -2.84981107 -0.9524646  0.673732\n2 -0.7062245 -0.7035549 0.1981972 0.2543214  0.09241588 -0.9524646  0.673732\n3 -0.7062245 -0.7035549 0.1981972 0.2543214  0.09241588  1.6472706  0.673732\n4 -0.7062245 -0.7035549 0.1981972 3.1144053  0.09241588 -0.9524646  0.673732\n5 -0.7062245 -0.7035549 0.1981972 0.2543214  0.09241588  0.5257479  0.673732\n6 -0.7062245 -0.7035549 0.1981972 0.2543214  0.09241588 -0.9524646 -3.066870\n        MINV      MVS        HYP         LVF         APL       ANES        PMB\n1 -1.9144844 0.190179 -0.3735556 -0.09049377 -0.01845303 -0.1917453 -0.0187271\n2  0.5310157 0.190179 -0.3735556 -0.09049377 -0.01845303 -0.1917453 -0.0187271\n3  0.5310157 0.190179 -0.3735556 -0.09049377 -0.01845303 -0.1917453 -0.0187271\n4  0.5310157 0.190179 -0.3735556 -0.09049377 -0.01845303 -0.1917453 -0.0187271\n5  0.5310157 0.190179 -0.3735556 -0.09049377 -0.01845303 -0.1917453 -0.0187271\n6  0.5310157 0.190179 -0.3735556 -0.09049377 -0.01845303  2.3652828 -0.0187271\n          INT        KINK       DISC       LVV       STKV       CCHL       ERLO\n1 -0.03581248 -0.06643384  2.4071300 0.5699623  0.4078339 -0.4523933 -0.0915921\n2 -0.03581248 -0.06643384 -0.1806935 0.5699623 -1.6350478 -0.4523933 -0.0915921\n3 -0.03581248 -0.06643384 -0.1806935 0.5699623  0.4078339 -0.4523933 -0.0915921\n4 -0.03581248 -0.06643384 -0.1806935 0.5699623  0.4078339 -0.4523933 -0.0915921\n5 -0.03581248 -0.06643384 -0.1806935 0.5699623  0.4078339 -0.4523933 -0.0915921\n6 -0.03581248 -0.06643384 -0.1806935 0.5699623  0.4078339 -0.4523933 -0.0915921\n          HR       ERCA     SHNT      PVS       ACO2      VALV       VLNG\n1 -0.5839908 -0.1820744 0.188705 3.335150  2.2090134 -1.919255 -1.6005522\n2 -0.5839908 -0.1820744 0.188705 0.284708 -0.2197939  0.573119  0.4766123\n3 -0.5839908 -0.1820744 0.188705 0.284708 -0.2197939  0.573119  0.4766123\n4 -0.5839908 -0.1820744 0.188705 3.335150 -0.2197939  0.573119  0.4766123\n5 -0.5839908 -0.1820744 0.188705 0.284708 -0.2197939  0.573119  0.4766123\n6 -0.5839908 -0.1820744 0.188705 0.284708 -0.2197939  0.573119  0.4766123\n       VTUB     VMCH\n1  1.903289 0.124569\n2 -0.274845 0.124569\n3 -0.274845 0.124569\n4 -0.274845 0.124569\n5 -0.274845 0.124569\n6 -0.274845 0.124569\nSubselecting certain variables for analysis. Splitting the data set\ninto the train (structure estimation) and the dataset for inference\n(given the structure of the estimated graph) on the particular\ncovariate. Correlation maps of the given sub-selection of variables is\npresented.\nWarning: The `x` argument of `as_tibble.matrix()` must have unique column names if\n`.name_repair` is omitted as of tibble 2.0.0.\nℹ Using compatibility `.name_repair`.\n\nDefining the true network structure for the alarm dataset (see paper\n“Learning Bayesian Networks with the bnlearn R Package” by\nM.Scutari)\ndag_alarm &lt;- empty.graph(names(alarm))\nmodelstring(dag_alarm) &lt;- paste(\"[HIST|LVF][CVP|LVV][PCWP|LVV][HYP][LVV|HYP:LVF]\",\"[LVF][STKV|HYP:LVF][ERLO][HRBP|ERLO:HR][HREK|ERCA:HR][ERCA][HRSA|ERCA:HR]\",\"[ANES][APL][TPR|APL][ECO2|ACO2:VLNG][KINK][MINV|INT:VLNG][FIO2]\",\"[PVS|FIO2:VALV][SAO2|PVS:SHNT][PAP|PMB][PMB][SHNT|INT:PMB][INT]\",\"[PRSS|INT:KINK:VTUB][DISC][MVS][VMCH|MVS][VTUB|DISC:VMCH]\",\"[VLNG|INT:KINK:VTUB][VALV|INT:VLNG][ACO2|VALV][CCHL|ACO2:ANES:SAO2:TPR]\",\"[HR|CCHL][CO|HR:STKV][BP|CO:TPR]\", sep = \"\")\nqgraph(dag_alarm)\n\nSelection of the specific covariates to perform the structure\nestimation and the inference in the model task.\nalarm_dfSubset &lt;-as.data.frame(alarm_df[,selection])\n\nalarm_df_str_est = alarm_dfSubset[str_set,]\nalarm_df_fit = alarm_dfSubset[est_set,]\nhead(alarm_df_str_est)\n  TPR PMB VTUB VLNG CO\n1   2   1    4    2  1\n2   3   1    2    4  2\n3   3   1    2    4  1\n4   2   1    2    4  1\n5   2   1    2    4  3\n6   2   1    2    4  1\nApplying the algorithm pc.stable to the dataset alarm\nRes&lt;-pc.stable(alarm_df_str_est)\n\nbnlearn:::print.bn(Res)\n\n  Bayesian network learned via Constraint-based methods\n\n  model:\n    [partially directed graph]\n  nodes:                                 5 \n  arcs:                                  3 \n    undirected arcs:                     1 \n    directed arcs:                       2 \n  average markov blanket size:           1.60 \n  average neighbourhood size:            1.20 \n  average branching factor:              0.40 \n\n  learning algorithm:                    PC (Stable) \n  conditional independence test:         Pearson's Correlation \n  alpha threshold:                       0.05 \n  tests used in the learning procedure:  28 \nApplying a set of constraint-based algorithms to estimate the DAG\nstructure between the selected variables.\nRes_stable=pc.stable(alarm_df_str_est)\n\nRes_iamb=iamb(alarm_df_str_est)\n\nRes_gs=gs(alarm_df_str_est)\n\nRes_fiamb=fast.iamb(alarm_df_str_est)\n\nRes_mmpc=mmpc(alarm_df_str_est)\nVisualizing the estimated graph with PC-stable algorithm with respect\nto the chosen variables. As we see the pc.stable algorithm returns a\nCPDAG. For the inference purposes we manually set the (undirected) edges\nto specific values.\nLabels &lt;- c(\n  \"Total peripheral resistance\",\n  \"Pulmonary embolus\",\n  \"Ventilation tube\",\n  \"Lung ventilation\",\n  \"Cardiac output\"\n)\n\nqgraph(Res, nodeNames = Labels, legend.cex = 0.35)\n\n# black magic to make it a proper DAG\n\nRes &lt;- set.arc(Res, from = \"PMB\",to=\"CO\")\nRes &lt;- set.arc(Res, from = \"TPR\",to=\"CO\")\nRes = set.arc(Res,from = \"VLNG\",to=\"VTUB\")\n\nRes\n\n  Bayesian network learned via Constraint-based methods\n\n  model:\n   [TPR][PMB][VLNG][VTUB|VLNG][CO|TPR:PMB:VLNG] \n  nodes:                                 5 \n  arcs:                                  4 \n    undirected arcs:                     0 \n    directed arcs:                       4 \n  average markov blanket size:           2.80 \n  average neighbourhood size:            1.60 \n  average branching factor:              0.80 \n\n  learning algorithm:                    PC (Stable) \n  conditional independence test:         Pearson's Correlation \n  alpha threshold:                       0.05 \n  tests used in the learning procedure:  28 \ngraph &lt;- qgraph(Res)\n\nFitting the model to the dataset.\nfit &lt;- bn.fit(Res, alarm_df_fit)\nfit$CO\n\n  Parameters of node CO (Gaussian distribution)\n\nConditional density: CO | TPR + PMB + VLNG\nCoefficients:\n(Intercept)          TPR          PMB         VLNG  \n 2.61248092  -0.39384628   0.01495855  -0.02626200  \nStandard deviation of the residuals: 0.7893206 \nfit$VTUB\n\n  Parameters of node VTUB (Gaussian distribution)\n\nConditional density: VTUB | VLNG\nCoefficients:\n(Intercept)         VLNG  \n  3.2383682   -0.2568879  \nStandard deviation of the residuals: 0.8209566 \nfit$TPR\n\n  Parameters of node TPR (Gaussian distribution)\n\nConditional density: TPR\nCoefficients:\n(Intercept)  \n   2.094853  \nStandard deviation of the residuals: 0.8253788 \nNonparametrical bootstraping of the results of the model.\nset.seed(1)\n\nboot &lt;- boot.strength(as.data.frame(alarm_dfSubset), R = 100, algorithm = \"pc.stable\")\n\nboot\n   from   to strength direction\n1   TPR  PMB     0.69 0.2318841\n2   TPR VTUB     0.05 0.1000000\n3   TPR VLNG     0.00 0.0000000\n4   TPR   CO     1.00 0.4750000\n5   PMB  TPR     0.69 0.7681159\n6   PMB VTUB     0.03 0.5000000\n7   PMB VLNG     0.10 0.5000000\n8   PMB   CO     0.01 1.0000000\n9  VTUB  TPR     0.05 0.9000000\n10 VTUB  PMB     0.03 0.5000000\n11 VTUB VLNG     1.00 0.7200000\n12 VTUB   CO     0.03 0.5000000\n13 VLNG  TPR     0.00 0.0000000\n14 VLNG  PMB     0.10 0.5000000\n15 VLNG VTUB     1.00 0.2800000\n16 VLNG   CO     1.00 0.4600000\n17   CO  TPR     1.00 0.5250000\n18   CO  PMB     0.01 0.0000000\n19   CO VTUB     0.03 0.5000000\n20   CO VLNG     1.00 0.5400000\nqgraph(boot,nodeNames=Labels,legend.cex = 0.35,\n       edge.labels=TRUE,layout=graph$layout,asize=5,\n       edge.color=\"black\")\n\nReferences \n[1] Beinlich I, Suermondt HJ, Chavez RM, Cooper GF (1989). “The ALARM\nMonitoring System: A Case Study with Two Probabilistic Inference\nTechniques for Belief Networks”. Proceedings of the 2nd European\nConference on Artificial Intelligence in Medicine, 247–256. https://doi.org/10.1007/978-3-642-93437-7_28\n[2] Scutari, M. Learning Bayesian Networks with bnlearn R package. https://arxiv.org/pdf/0908.3817.pdf",
    "crumbs": [
      "Accompanying Statistical Notebooks",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>online html</span>"
    ]
  },
  {
    "objectID": "gallery.html",
    "href": "gallery.html",
    "title": "Accompanying Statistical Notebooks",
    "section": "",
    "text": "Gallery with Links\n    \n\n\n    For more information and content of the projects, click on respective window.\n    \n        \n        \n             Gaussian  Linear Model\n            \n                \n            \n            \n                Git\n                Zenodo\n            \n        \n        \n        \n            ALARM  Notebook\n            \n                \n            \n            \n                Git\n                Zenodo\n            \n        \n        \n        \n            ALARM Subgraph Notebook\n            \n                \n            \n            \n                Git\n                Zenodo\n            \n        \n        \n        \n            Cause-Effect Pairs MPI Tuebingen\n            \n                \n            \n            \n                Git\n                Zenodo\n            \n        \n        \n        \n            online html\n            \n                \n            \n            \n                Git\n                Zenodo",
    "crumbs": [
      "Accompanying Statistical Notebooks"
    ]
  }
]